{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5e7a63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lucene\n",
    "import numpy as np\n",
    "import chinese_converter\n",
    "import ir_measures\n",
    "from ir_measures import *\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.ru import RussianAnalyzer\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.analysis.core import WhitespaceAnalyzer\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a43b01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM is already running, options are ineffective\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyLucene\n",
    "try:\n",
    "    lucene.initVM(lucene.CLASSPATH, maxheap='3g')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "b9ea066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_docid_lang.txt') as f: \n",
    "    data = f.read() \n",
    "dict_docid_lang = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "a03af5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_of_Retrieved_Docs = 1000\n",
    "dict_clir_id_text = {}\n",
    "dict_topic_lang_score_normal_rel = {}\n",
    "dict_qrels_topic_id_doc_id = {}\n",
    "dict_topic_id_topic_description_eng = {}\n",
    "dict_user_query = {}\n",
    "dict_id_english_text = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "60fd4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Discounted Cumulative Gain (DCG)\n",
    "def calculate_dcg(relevance_scores):\n",
    "    return np.sum([((2 ** rel) - 1) / np.log2(rank + 2) for rank, rel in enumerate(relevance_scores)])\n",
    "\n",
    "def min_max_normalization(scores):\n",
    "    min_score = min(scores)\n",
    "    max_score = max(scores)\n",
    "    normalized_scores = [(score - min_score) / (max_score - min_score) for score in scores]\n",
    "    return normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c575f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratios_doclist(dict_docid_lang, doclist):\n",
    "    count_fas = 0\n",
    "    count_rus = 0\n",
    "    count_zho = 0\n",
    "    for docid in doclist: \n",
    "        if dict_docid_lang[docid] == 'fas': \n",
    "            count_fas = count_fas + 1\n",
    "        elif dict_docid_lang[docid] == 'rus': \n",
    "            count_rus = count_rus + 1\n",
    "        elif dict_docid_lang[docid] == 'zho': \n",
    "            count_zho = count_zho + 1\n",
    "    total = count_fas + count_rus + count_zho\n",
    "    return count_fas/total, count_rus/total, count_zho/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "685cb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratios_run_file(dict_docid_lang, run_file, k=0):\n",
    "    ratios_fas = []\n",
    "    ratios_rus = []\n",
    "    ratios_zho = []\n",
    "    dict_qid_doclist = {}\n",
    "    with open(run_file) as f: \n",
    "        for line in f:\n",
    "            data = line.split()\n",
    "            qid = data[0]\n",
    "            if qid not in dict_qid_doclist:\n",
    "                dict_qid_doclist[qid] = []\n",
    "            dict_qid_doclist[qid].append(data[2])\n",
    "    for qid in dict_qid_doclist:\n",
    "        doclist = dict_qid_doclist[qid]\n",
    "        if k == 0:\n",
    "            k = len(doclist)\n",
    "        doclist = doclist[:k]\n",
    "        r_fas, r_rus, r_zho = get_ratios_doclist(dict_docid_lang, doclist)\n",
    "        ratios_fas.append(r_fas)\n",
    "        ratios_rus.append(r_rus)\n",
    "        ratios_zho.append(r_zho)\n",
    "    return sum(ratios_fas)/len(ratios_fas), sum(ratios_rus)/len(ratios_rus), sum(ratios_zho)/len(ratios_zho)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d6b3a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_dcg(relevance, ranking, alpha=0.5):\n",
    "    dcg = 0.0\n",
    "    topic_coverage = {}\n",
    "    for rank, doc_id in enumerate(ranking):\n",
    "        if doc_id not in relevance:\n",
    "            continue        \n",
    "        scores = relevance[doc_id]\n",
    "        gain_sum = 0.0\n",
    "        for topic_idx, score in enumerate(scores):\n",
    "            if score > 0:\n",
    "                if topic_idx not in topic_coverage:\n",
    "                    topic_coverage[topic_idx] = 0\n",
    "                gain = score * (1 - alpha) ** topic_coverage[topic_idx]\n",
    "                gain_sum += gain\n",
    "                topic_coverage[topic_idx] += 1\n",
    "        dcg += gain_sum / np.log2(rank + 2) \n",
    "    return dcg\n",
    "\n",
    "def ideal_alpha_dcg(relevance, alpha=0.5):\n",
    "    sorted_docs = sorted(relevance.keys(), key=lambda doc_id: sum(relevance[doc_id]), reverse=True)\n",
    "    return alpha_dcg(relevance, sorted_docs, alpha)\n",
    "\n",
    "def alpha_ndcg(relevance, ranking, alpha=0.5):\n",
    "    dcg = alpha_dcg(relevance, ranking, alpha)\n",
    "    idcg = ideal_alpha_dcg(relevance, alpha)\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bf6de8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_rel_lang(dict_docid_lang, dict_qrels_topic_id_doc_id, qid, docid):\n",
    "    rel_fas_rus_zho = [0, 0, 0]\n",
    "    rel = 0\n",
    "    if docid in dict_qrels_topic_id_doc_id[qid]: \n",
    "        rel = dict_qrels_topic_id_doc_id[qid][docid]\n",
    "    if dict_docid_lang[docid] == 'fas':\n",
    "        rel_fas_rus_zho[0] = rel\n",
    "    elif dict_docid_lang[docid] == 'rus':\n",
    "        rel_fas_rus_zho[1] = rel\n",
    "    elif dict_docid_lang[docid] == 'zho':\n",
    "        rel_fas_rus_zho[2] = rel\n",
    "    return rel_fas_rus_zho    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "376c5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_ndcg_run_file(dict_docid_lang, dict_qrels_topic_id_doc_id, run_file, alpha, k=0):\n",
    "    alpha_ndcgs_list = []\n",
    "    dict_qid_doclist = {}\n",
    "    with open(run_file) as f: \n",
    "        for line in f:\n",
    "            data = line.split()\n",
    "            qid = data[0]\n",
    "            if qid not in dict_qid_doclist:\n",
    "                dict_qid_doclist[qid] = []\n",
    "            dict_qid_doclist[qid].append(data[2])\n",
    "    for qid in dict_qid_doclist:\n",
    "        doclist = dict_qid_doclist[qid]\n",
    "        if k == 0:\n",
    "            k = len(doclist)\n",
    "        doclist = doclist[:k]\n",
    "        relevance = {}\n",
    "        for docid in doclist:\n",
    "            relevance[docid] = get_doc_rel_lang(dict_docid_lang, dict_qrels_topic_id_doc_id, qid, docid)\n",
    "        alpha_ndcgs_list.append(alpha_ndcg(relevance, doclist, alpha))\n",
    "    return sum(alpha_ndcgs_list)/len(alpha_ndcgs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f5f47c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [t for t in map(json.loads, open(\"neuclir-2023-topics.0605.jsonl\"))]\n",
    "for t in topics:\n",
    "    for topic in t['topics']: \n",
    "        if topic['lang'] == 'eng':\n",
    "            dict_topic_id_topic_description_eng[t['topic_id']] = topic['topic_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "da6dd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qrels.final\", \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    for line in lines: \n",
    "        cols = line.strip().split()\n",
    "        topic_id = cols[0]\n",
    "        doc_id = cols[2]\n",
    "        qrels = int(cols[3])\n",
    "        if topic_id in dict_qrels_topic_id_doc_id: \n",
    "            dict_qrels_topic_id_doc_id[topic_id][doc_id] = qrels\n",
    "        else: \n",
    "            dict_qrels_topic_id_doc_id[topic_id] = {}\n",
    "            dict_qrels_topic_id_doc_id[topic_id][doc_id] = qrels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "682c9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_user_query = {}\n",
    "for t in topics:\n",
    "    user_query = {}\n",
    "    for topic in t['topics']: \n",
    "        if topic['lang'] == 'eng': \n",
    "            user_query[topic['lang']] = topic['topic_title']\n",
    "        else: \n",
    "            if topic['source'] == 'google translation':\n",
    "                if topic['lang'] == 'zho':\n",
    "                    user_query[topic['lang']] = chinese_converter.to_simplified(topic['topic_title'])\n",
    "                    #user_query[topic['lang']] = topic['topic_title']\n",
    "                else:\n",
    "                    user_query[topic['lang']] = topic['topic_title']\n",
    "    dict_user_query[t['topic_id']] = user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "272646ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_analyzer = RussianAnalyzer()\n",
    "english_analyzer = EnglishAnalyzer()\n",
    "whitespace_analyzer = WhitespaceAnalyzer()\n",
    "\n",
    "# Open the Lucene indexes\n",
    "index_directory_rus = FSDirectory.open(Paths.get(\"/path/neuclir1/index_rus\"))\n",
    "index_directory_eng = FSDirectory.open(Paths.get(\"/path/neuclir1/index_eng\"))\n",
    "# Use IndexSearcher to search the index\n",
    "index_searcher_rus = IndexSearcher(DirectoryReader.open(index_directory_rus))\n",
    "index_searcher_rus.setSimilarity(BM25Similarity())\n",
    "index_searcher_eng = IndexSearcher(DirectoryReader.open(index_directory_eng))\n",
    "index_searcher_eng.setSimilarity(BM25Similarity())\n",
    "# Create a QueryParser with the same analyzer used during indexing\n",
    "query_parser_rus = QueryParser(\"titletext\", russian_analyzer)\n",
    "query_parser_eng = QueryParser(\"titletext\", english_analyzer)\n",
    "query_parser_id = QueryParser(\"id\", whitespace_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "dafb6fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32056/2719320574.py:46: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ndcg = dcg / idcg\n"
     ]
    }
   ],
   "source": [
    "for key in dict_user_query: \n",
    "    query_topic_id = key\n",
    "    user_query = dict_user_query[key]\n",
    "    if 'rus' not in user_query:\n",
    "        continue\n",
    "    #print(key, user_query['rus'])\n",
    "    parsed_query_rus = query_parser_rus.parse(user_query['rus'])    \n",
    "    search_results_rus = index_searcher_rus.search(parsed_query_rus, Num_of_Retrieved_Docs)\n",
    "    results_scores_rus = []\n",
    "    results_scores_rus_id = []\n",
    "    dict_id_score = {}\n",
    "    # Process search results\n",
    "    for score_doc in search_results_rus.scoreDocs:\n",
    "        results_scores_rus.append(score_doc.score)\n",
    "        doc_id = score_doc.doc\n",
    "        #print(doc_id)\n",
    "        doc = index_searcher_rus.doc(doc_id)\n",
    "        id = doc.get(\"id\")\n",
    "        #title = doc.get(\"title\")\n",
    "        text = doc.get(\"titletext\")\n",
    "        #url = doc.get(\"url\")\n",
    "        dict_clir_id_text[id] = text\n",
    "        results_scores_rus_id.append(id)\n",
    "        dict_id_score[id] = score_doc.score\n",
    "    ranked_list = results_scores_rus_id\n",
    "    #print(ranked_list)\n",
    "    relevance_scores = []\n",
    "    for i in range(len(ranked_list)):\n",
    "        doc_id = ranked_list[i]\n",
    "        if doc_id in dict_qrels_topic_id_doc_id[query_topic_id]: \n",
    "            relevance_scores.append(dict_qrels_topic_id_doc_id[query_topic_id][doc_id])\n",
    "        else: \n",
    "            relevance_scores.append(0)\n",
    "    if key not in dict_topic_lang_score_normal_rel:\n",
    "        dict_topic_lang_score_normal_rel[key] = {}\n",
    "    dict_topic_lang_score_normal_rel[key]['rus'] = []\n",
    "    dict_topic_lang_score_normal_rel[key]['rus'].append(list(zip(results_scores_rus, relevance_scores)))\n",
    "    dict_topic_lang_score_normal_rel[key]['rus'].append(list(zip(min_max_normalization(results_scores_rus), relevance_scores)))\n",
    "    dict_topic_lang_score_normal_rel[key]['rus'].append(ranked_list)\n",
    "    dcg = calculate_dcg(relevance_scores)\n",
    "    # Calculate Ideal Discounted Cumulative Gain (IDCG)\n",
    "    ideal_relevance_scores = sorted(relevance_scores, reverse=True)\n",
    "    idcg = calculate_dcg(ideal_relevance_scores)\n",
    "    # Calculate NDCG score\n",
    "    ndcg = dcg / idcg\n",
    "    # print(\"Discounted Cumulative Gain (DCG):\", dcg)\n",
    "    # print(\"Ideal Discounted Cumulative Gain (IDCG):\", idcg)\n",
    "    # print(\"NDCG score:\", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "836ddd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_user_query: \n",
    "    query_topic_id = key\n",
    "    user_query = dict_user_query[key]\n",
    "    # Parse the user's query\n",
    "    if 'eng' not in user_query:\n",
    "        continue\n",
    "    #print(key, user_query['eng'])\n",
    "    parsed_query_eng = query_parser_eng.parse(user_query['eng'])    \n",
    "    #parsed_query_eng = query_parser_eng.parse(dict_topic_id_topic_description_eng[key].replace('/', ' ') )\n",
    "    search_results_eng = index_searcher_eng.search(parsed_query_eng, Num_of_Retrieved_Docs)\n",
    "    results_scores_eng = []\n",
    "    results_scores_eng_id = []\n",
    "    dict_id_score = {}\n",
    "    # Process search results\n",
    "    for score_doc in search_results_eng.scoreDocs:\n",
    "        results_scores_eng.append(score_doc.score)\n",
    "        doc_id = score_doc.doc\n",
    "        #print(doc_id)\n",
    "        doc = index_searcher_eng.doc(doc_id)\n",
    "        title = doc.get(\"title\")\n",
    "        titletext = doc.get(\"titletext\")\n",
    "        url = doc.get(\"url\")\n",
    "        id = doc.get(\"id\")\n",
    "        dict_id_english_text[id] = titletext\n",
    "        results_scores_eng_id.append(id)\n",
    "        dict_id_score[id] = score_doc.score\n",
    "    ranked_list = results_scores_eng_id\n",
    "    #print(ranked_list)\n",
    "    relevance_scores = []\n",
    "    for i in range(len(ranked_list)):\n",
    "        doc_id = ranked_list[i]\n",
    "        if doc_id in dict_qrels_topic_id_doc_id[query_topic_id]: \n",
    "            relevance_scores.append(dict_qrels_topic_id_doc_id[query_topic_id][doc_id])\n",
    "        else: \n",
    "            relevance_scores.append(0)\n",
    "    if key not in dict_topic_lang_score_normal_rel:\n",
    "        dict_topic_lang_score_normal_rel[key] = {}\n",
    "    dict_topic_lang_score_normal_rel[key]['eng'] = []\n",
    "    dict_topic_lang_score_normal_rel[key]['eng'].append(list(zip(results_scores_eng, relevance_scores)))\n",
    "    dict_topic_lang_score_normal_rel[key]['eng'].append(list(zip(min_max_normalization(results_scores_eng), relevance_scores)))\n",
    "    dict_topic_lang_score_normal_rel[key]['eng'].append(ranked_list)\n",
    "    dcg = calculate_dcg(relevance_scores)\n",
    "    # Calculate Ideal Discounted Cumulative Gain (IDCG)\n",
    "    ideal_relevance_scores = sorted(relevance_scores, reverse=True)\n",
    "    idcg = calculate_dcg(ideal_relevance_scores)\n",
    "    # Calculate NDCG score\n",
    "    ndcg = dcg / idcg\n",
    "    # print(\"Discounted Cumulative Gain (DCG):\", dcg)\n",
    "    # print(\"Ideal Discounted Cumulative Gain (IDCG):\", idcg)\n",
    "    # print(\"NDCG score:\", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0e45055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rus-teamli-1ANRS_run1', 'w') as f: \n",
    "    for key in dict_topic_lang_score_normal_rel:\n",
    "        ranked_docs = dict_topic_lang_score_normal_rel[key]['rus'][2]\n",
    "        for i in range(len(ranked_docs)):\n",
    "            print(key, 'Q0', ranked_docs[i], i+1, dict_topic_lang_score_normal_rel[key]['rus'][1][i][0], 'rus-teamli-1ANRS_run1', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b59961d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useNormalizedScore = 0 to use original score from Lucene\n",
    "def merge_lang_ranked_list(topic_id, dict_topic_lang_score_normal_rel, useNormalizedScore=1):\n",
    "    ranked_docs_socre = []\n",
    "    for lang in dict_topic_lang_score_normal_rel[topic_id]:\n",
    "        if lang != 'eng':\n",
    "            ranked_docs_socre = ranked_docs_socre + [(y, x[0]) for x, y in zip(dict_topic_lang_score_normal_rel[topic_id][lang][useNormalizedScore], dict_topic_lang_score_normal_rel[topic_id][lang][2])]\n",
    "    return sorted(ranked_docs_socre, key=lambda x: x[1], reverse=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "a511e79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AP@100: 0.16993121086540244,\n",
       " R@100: 0.41112786398896123,\n",
       " AP@1000: 0.18373700018666103,\n",
       " nDCG@20: 0.2648281822438968,\n",
       " R@50: 0.3357662416561444,\n",
       " R@1000: 0.6296066780610262,\n",
       " AP@20: 0.13145052754798997,\n",
       " R@20: 0.24778217197711866,\n",
       " AP@50: 0.15733605015749388,\n",
       " nDCG@50: 0.2908655759243969}"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qrels = ir_measures.read_trec_qrels('qrels.final.gains.rus')\n",
    "qrels = ir_measures.read_trec_qrels('qrels.final.gains.rus')\n",
    "run = ir_measures.read_trec_run('rus-teamli-1ANRS_run1')\n",
    "ir_measures.calc_aggregate([nDCG@20, nDCG@50, R@20, R@50, R@100, R@1000, AP@20, AP@50, AP@100, AP@1000], qrels, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "efd5838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5397001861500951\n"
     ]
    }
   ],
   "source": [
    "print(get_alpha_ndcg_run_file(dict_docid_lang, dict_qrels_topic_id_doc_id, 'rus-teamli-1ANRS_run1', 0.5, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "93eb877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translated_title_text_by_id(doc_id, index_searcher_eng, query_parser_id): \n",
    "    query_id = query_parser_id.parse(doc_id)\n",
    "    #print(query_id)\n",
    "    search_results = index_searcher_eng.search(query_id, 1)\n",
    "    str_to_get = ''\n",
    "    for score_doc in search_results.scoreDocs:\n",
    "        tmp_id = score_doc.doc\n",
    "        doc = index_searcher_eng.doc(tmp_id)\n",
    "        str_to_get = str_to_get + doc.get(\"titletext\") + ' '\n",
    "    return str_to_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "e06a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_topic_title_english_doc_score1 = {}\n",
    "#model1 = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", max_length=512)\n",
    "model1 = CrossEncoder(\"cross-encoder/ms-marco-TinyBERT-L-2-v2\", max_length=512)\n",
    "for topic_id in dict_topic_lang_score_normal_rel:\n",
    "    doc_id_list = dict_topic_lang_score_normal_rel[topic_id]['rus'][2]\n",
    "    #query = dict_user_query[topic_id]['eng']\n",
    "    query = dict_topic_id_topic_description_eng[topic_id]\n",
    "    #query = dict_user_query[topic_id]['eng']+ ' ' +dict_topic_id_topic_description_eng[topic_id]\n",
    "    english_docs_list = []\n",
    "    query_list = []\n",
    "    for i in range(len(doc_id_list)):\n",
    "        tmp_id = doc_id_list[i]\n",
    "        english_docs_list.append(get_translated_title_text_by_id(tmp_id, index_searcher_eng, query_parser_id))\n",
    "        query_list.append(query)\n",
    "    scores = model1.predict(list(zip(query_list, english_docs_list)))\n",
    "    dict_topic_title_english_doc_score1[topic_id] = sorted(zip(doc_id_list, scores), key = lambda x : x[1], reverse = True)\n",
    "\n",
    "with open('clir-test_run_rus', 'w') as f: \n",
    "    for topic_id in dict_topic_title_english_doc_score1:\n",
    "        ranked_docs_socres = dict_topic_title_english_doc_score1[topic_id]\n",
    "        for i in range(len(ranked_docs_socres)):\n",
    "            print(topic_id, 'Q0', ranked_docs_socres[i][0], i+1, ranked_docs_socres[i][1], 'clir-test_run_rus', file=f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "38dbb15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.4399980893814571,\n",
       " nDCG@20: 0.31993517678511546,\n",
       " R@50: 0.35398365603351795,\n",
       " R@1000: 0.6296066780610262,\n",
       " R@20: 0.2476378962228813,\n",
       " nDCG@50: 0.3385564986582801}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = ir_measures.read_trec_qrels('qrels.final.gains.rus')\n",
    "run = ir_measures.read_trec_run('clir-test_run_rus')\n",
    "ir_measures.calc_aggregate([nDCG@20, nDCG@50, R@20, R@50, R@100, R@1000], qrels, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "8288099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6013862660432879\n"
     ]
    }
   ],
   "source": [
    "print(get_alpha_ndcg_run_file(dict_docid_lang, dict_qrels_topic_id_doc_id, 'clir-test_run_rus', 0.5, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Lucene index readers\n",
    "index_searcher_rus.getIndexReader().close()\n",
    "index_searcher_eng.getIndexReader().close()\n",
    "\n",
    "# Close the Lucene index directories\n",
    "index_directory_rus.close()\n",
    "index_directory_eng.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
